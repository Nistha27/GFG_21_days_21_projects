# 21 Days 21 Projects: AI and Machine Learning Journey

## Repository Overview

This repository contains a comprehensive collection of 21 AI and Machine Learning projects completed over 21 days. Each project demonstrates practical applications of various AI/ML techniques, from data analysis and visualization to advanced deep learning, natural language processing, and workflow automation.

## Repository Description

A complete hands-on journey through modern AI and Machine Learning technologies, featuring 21 progressively challenging projects covering data science, computer vision, NLP, generative AI, and intelligent automation. Each project includes detailed documentation, working code, and real-world applications.

## Table of Contents

- [Project List](#project-list)
- [Technologies Used](#technologies-used)
- [Repository Structure](#repository-structure)
- [Getting Started](#getting-started)
- [Project Categories](#project-categories)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Project List

### Week 1: Data Science Fundamentals

#### Day 01: Data Storytelling - Analyzing Survival on the Titanic
- **Focus**: Exploratory Data Analysis, Data Visualization
- **Technologies**: Python, Pandas, Matplotlib, Seaborn
- **Key Concepts**: Data cleaning, statistical analysis, visualization techniques
- **Deliverables**: Comprehensive Titanic survival analysis with insights

#### Day 02: Cracking the Code - Netflix Content Strategy Analysis
- **Focus**: Content Analysis, Business Intelligence
- **Technologies**: Python, Pandas, Plotly
- **Key Concepts**: Content distribution analysis, trend identification
- **Deliverables**: Netflix content strategy insights and visualizations

#### Day 03: Predicting Housing Market Trends with AI
- **Focus**: Regression Analysis, Predictive Modeling
- **Technologies**: Scikit-learn, XGBoost, Feature Engineering
- **Key Concepts**: Linear regression, ensemble methods, model evaluation
- **Deliverables**: Housing price prediction model with submission file

#### Day 04: AI in Healthcare - Heart Disease Predictor
- **Focus**: Classification, Healthcare AI
- **Technologies**: Scikit-learn, Logistic Regression, Random Forest
- **Key Concepts**: Binary classification, medical data analysis, model optimization
- **Deliverables**: Heart disease prediction system

#### Day 05: Smart Segmentation - Customer Personas with AI
- **Focus**: Clustering, Unsupervised Learning
- **Technologies**: K-Means, DBSCAN, PCA
- **Key Concepts**: Customer segmentation, dimensionality reduction
- **Deliverables**: Customer persona identification system

#### Day 06: Predicting Future Store Sales with AI
- **Focus**: Time Series Analysis, Forecasting
- **Technologies**: ARIMA, Prophet, LSTM
- **Key Concepts**: Temporal patterns, seasonal decomposition, forecasting
- **Deliverables**: Store sales prediction model

#### Day 07: Preventing Customer Churn with Feature Transformation
- **Focus**: Classification, Feature Engineering
- **Technologies**: Scikit-learn, Feature Transformation
- **Key Concepts**: Churn prediction, feature scaling, model selection
- **Deliverables**: Customer churn prevention system

### Week 2: Computer Vision and Deep Learning

#### Day 08: Vision AI Fundamentals - Digit Recognizer from Scratch
- **Focus**: Neural Networks, Image Classification
- **Technologies**: TensorFlow, Keras, CNN
- **Key Concepts**: Deep learning basics, convolutional networks, MNIST/CIFAR-100
- **Deliverables**: Digit recognition system with multiple model architectures

#### Day 09: Advanced Vision AI - Transfer Learning for Image Classification
- **Focus**: Transfer Learning, Pre-trained Models
- **Technologies**: TensorFlow, VGG16, ResNet, MobileNet
- **Key Concepts**: Fine-tuning, feature extraction, Oxford Flowers dataset
- **Deliverables**: Flower classification system using transfer learning

#### Day 10: Creative AI - Generating Art with Neural Style Transfer
- **Focus**: Generative AI, Style Transfer
- **Technologies**: TensorFlow, VGG19, GANs
- **Key Concepts**: Neural style transfer, artistic rendering, face generation
- **Deliverables**: Art generation system with gender-based style transfer

#### Day 11: The AI Swiss Army Knife - Hugging Face Pipelines
- **Focus**: Pre-trained Models, NLP
- **Technologies**: Hugging Face Transformers, Diffusion Models
- **Key Concepts**: One-line AI solutions, text generation, image synthesis
- **Deliverables**: Multi-purpose AI toolkit with diffusion model implementation

#### Day 12: Face Super Resolution and Object Detection with YOLO
- **Focus**: Computer Vision, Object Detection
- **Technologies**: YOLO, U-Net, OpenCV
- **Key Concepts**: Real-time detection, image enhancement, face resolution
- **Deliverables**: Object detection system and face super-resolution model

#### Day 13: Stock Price Prediction - NIFTY 50 Analysis
- **Focus**: Financial AI, Time Series
- **Technologies**: LSTM, GRU, Technical Indicators
- **Key Concepts**: Stock market prediction, sequential modeling
- **Deliverables**: NIFTY 50 stock price prediction system

#### Day 14: Build Your Own GPT - Custom Text Generation Engine
- **Focus**: Language Models, Text Generation
- **Technologies**: GPT-2, Transformers, Fine-tuning
- **Key Concepts**: Language model training, text generation, code generation
- **Deliverables**: Python code-focused GPT-2 model

### Week 3: Advanced NLP and Intelligent Systems

#### Day 15: Talk to Your Data - Natural Language to SQL Generator
- **Focus**: NLP, Database Querying
- **Technologies**: LangChain, SQL, NL2SQL
- **Key Concepts**: Natural language understanding, query generation
- **Deliverables**: Employee dataset analysis with NL2SQL interface

#### Day 16: Intelligent Document Automation - Smart OCR Bot
- **Focus**: OCR, Document Processing
- **Technologies**: Tesseract, OpenCV, NLP
- **Key Concepts**: Text extraction, document analysis, resume parsing
- **Deliverables**: Automated resume analysis system

#### Day 17: Build Your Own Intelligent Internet Search Engine
- **Focus**: Information Retrieval, Search Systems
- **Technologies**: TF-IDF, Vector Search, Web Scraping
- **Key Concepts**: Search algorithms, ranking, relevance scoring
- **Deliverables**: Custom search engine implementation

#### Day 18: Chat with Your Knowledge Base - RAG Chatbot
- **Focus**: Retrieval Augmented Generation, Chatbots
- **Technologies**: LangChain, Vector Databases, Embeddings
- **Key Concepts**: RAG architecture, semantic search, conversational AI
- **Deliverables**: Knowledge base chatbot system

#### Day 19: Autonomous Market Analyst - AI Agents for Deep Research
- **Focus**: AI Agents, Autonomous Systems
- **Technologies**: LangChain Agents, Tool Integration
- **Key Concepts**: Agent-based systems, autonomous research, tool usage
- **Deliverables**: Automated market research agent

#### Day 20: Web Automation on Autopilot - AI Browser Agent
- **Focus**: Web Automation, Browser Control
- **Technologies**: Selenium, AI Agents, Web Scraping
- **Key Concepts**: Automated browsing, intelligent navigation
- **Deliverables**: AI-powered browser automation system

#### Day 21: Building an AI-Powered Newsletter Pipeline on n8n
- **Focus**: Workflow Automation, Content Generation
- **Technologies**: n8n, AI Agents, RSS Feeds, Tavily
- **Key Concepts**: Workflow automation, content pipelines, AI integration
- **Deliverables**: Automated newsletter generation system

## Technologies Used

### Programming Languages
- Python 3.8+
- JavaScript (for n8n workflows)
- SQL

### Machine Learning Frameworks
- TensorFlow / Keras
- PyTorch
- Scikit-learn
- XGBoost
- LightGBM

### Deep Learning
- Convolutional Neural Networks (CNN)
- Recurrent Neural Networks (RNN/LSTM/GRU)
- Generative Adversarial Networks (GANs)
- Transformers
- Diffusion Models

### NLP and LLMs
- Hugging Face Transformers
- LangChain
- GPT-2
- BERT
- Sentence Transformers

### Computer Vision
- OpenCV
- YOLO
- Tesseract OCR
- PIL/Pillow

### Data Science
- Pandas
- NumPy
- Matplotlib
- Seaborn
- Plotly

### Automation and Tools
- n8n
- Selenium
- Beautiful Soup
- Requests

### Databases and Storage
- Vector Databases
- SQL
- CSV/Excel

## Repository Structure

Each day contains:
- Tutorial notebooks explaining concepts
- Assignment notebooks with complete solutions
- Dedicated README with project details
- Data files and model weights where applicable

```
21_days_21_projects/
├── README.md                           # This file
├── .gitignore                          # Git ignore rules
├── 21-Days-21-Projects-Dataset/        # Shared datasets
├── Day_01/ ... Day_21/                 # 21 project folders
│   ├── Tutorial notebooks
│   ├── Assignment solutions
│   ├── Data files
│   └── README.md
```

For detailed file structure, see [STRUCTURE.md](STRUCTURE.md)

## Getting Started

### Prerequisites

- Python 3.8 or higher
- Jupyter Notebook or JupyterLab
- Git
- Virtual environment tool (venv or conda)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/Khanna-Aman/GFG_21_days_21_projects.git
cd GFG_21_days_21_projects
```

2. Create and activate virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install required packages for specific projects:
```bash
cd Day_XX
pip install -r requirements.txt  # If available
```

## Usage

Each day's project is self-contained in its respective folder. To run a project:

1. Navigate to the specific day folder
2. Open the Jupyter notebook or Python script
3. Follow the instructions in the project's README.md
4. Execute cells sequentially or run the script

Example:
```bash
cd Day_01
jupyter notebook Assignment_titanic_analysis.ipynb
```

## Project Categories

### Data Science and Analytics
Days 1, 2, 3, 5, 6, 7, 13, 15

### Computer Vision
Days 8, 9, 10, 12, 16

### Natural Language Processing
Days 11, 14, 15, 18

### Intelligent Automation
Days 17, 19, 20, 21

### Healthcare AI
Day 4

## Contributing

This is a personal learning repository. However, suggestions and improvements are welcome through issues and pull requests.

## License

This project is available for educational purposes. Individual projects may have different licenses based on the datasets and libraries used.

## Acknowledgments

- GeeksforGeeks for the 21 Days 21 Projects challenge
- Open-source community for various libraries and tools
- Dataset providers and API services

## Contact

For questions or collaboration opportunities, please open an issue in this repository.

---

**Note**: Each project folder contains its own detailed README with specific instructions, requirements, and documentation.

