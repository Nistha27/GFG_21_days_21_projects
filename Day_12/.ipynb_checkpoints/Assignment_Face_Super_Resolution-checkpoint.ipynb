{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Face Super-Resolution with U-Net - Real CelebA Dataset\n",
                "\n",
                "**Assignment Goal**: Take a low-resolution face image (64x64 pixels) as input and produce a high-resolution, enhanced face image (256x256 pixels) using a U-Net model.\n",
                "\n",
                "## Key Features:\n",
                "- 4x super-resolution (64x64 → 256x256)\n",
                "- Real CelebA face dataset (38,765 images)\n",
                "- CPU-optimized for local execution\n",
                "- Lightweight U-Net architecture\n",
                "- Visual comparison of results\n",
                "\n",
                "**Dataset**: Using extracted CelebA dataset from Day_12/celeba_dataset/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import cv2\n",
                "from sklearn.model_selection import train_test_split\n",
                "import random\n",
                "\n",
                "# TensorFlow with CPU optimization\n",
                "import tensorflow as tf\n",
                "tf.config.set_visible_devices([], 'GPU')  # Force CPU usage\n",
                "print(f\"TensorFlow version: {tf.__version__}\")\n",
                "print(f\"Using CPU only (GPU disabled)\")\n",
                "\n",
                "from tensorflow.keras.models import Model\n",
                "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D\n",
                "from tensorflow.keras.layers import BatchNormalization, Activation, concatenate\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
                "\n",
                "print(\"All imports successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Load Real CelebA Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset path\n",
                "dataset_path = './celeba_dataset/img_align_celeba/img_align_celeba/'\n",
                "\n",
                "# Check if dataset exists\n",
                "if not os.path.exists(dataset_path):\n",
                "    print(f\"Dataset not found at {dataset_path}\")\n",
                "    print(\"Please make sure the CelebA dataset is extracted in the correct location.\")\n",
                "    raise FileNotFoundError(\"CelebA dataset not found\")\n",
                "\n",
                "# Get list of all image files\n",
                "image_files = [f for f in os.listdir(dataset_path) if f.lower().endswith('.jpg')]\n",
                "print(f\"Found {len(image_files)} images in dataset\")\n",
                "\n",
                "# For CPU training, use a subset of images\n",
                "num_samples = min(2000, len(image_files))  # Use 2000 images for CPU training\n",
                "selected_files = random.sample(image_files, num_samples)\n",
                "print(f\"Selected {num_samples} images for training\")\n",
                "\n",
                "def load_and_preprocess_image(image_path):\n",
                "    \"\"\"Load and preprocess a single image\"\"\"\n",
                "    try:\n",
                "        # Load image\n",
                "        img = cv2.imread(image_path)\n",
                "        if img is None:\n",
                "            return None, None\n",
                "        \n",
                "        # Convert BGR to RGB\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        # Resize to 256x256 for high-resolution target\n",
                "        img_256 = cv2.resize(img, (256, 256))\n",
                "        \n",
                "        # Create 64x64 low-resolution version\n",
                "        img_64 = cv2.resize(img_256, (64, 64))\n",
                "        \n",
                "        # Normalize to [0, 1]\n",
                "        img_256 = img_256.astype(np.float32) / 255.0\n",
                "        img_64 = img_64.astype(np.float32) / 255.0\n",
                "        \n",
                "        return img_64, img_256\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing image {image_path}: {e}\")\n",
                "        return None, None\n",
                "\n",
                "# Load dataset\n",
                "print(\"Loading and preprocessing images...\")\n",
                "X_data = []  # 64x64 inputs\n",
                "y_data = []  # 256x256 targets\n",
                "\n",
                "for i, filename in enumerate(selected_files):\n",
                "    if i % 200 == 0:\n",
                "        print(f\"Processed {i}/{num_samples} images...\")\n",
                "    \n",
                "    image_path = os.path.join(dataset_path, filename)\n",
                "    img_64, img_256 = load_and_preprocess_image(image_path)\n",
                "    \n",
                "    if img_64 is not None and img_256 is not None:\n",
                "        X_data.append(img_64)\n",
                "        y_data.append(img_256)\n",
                "\n",
                "# Convert to numpy arrays\n",
                "X_data = np.array(X_data)\n",
                "y_data = np.array(y_data)\n",
                "\n",
                "print(f\"\\nDataset loaded successfully!\")\n",
                "print(f\"Input shape: {X_data.shape}\")\n",
                "print(f\"Target shape: {y_data.shape}\")\n",
                "\n",
                "# Display sample images\n",
                "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
                "for i in range(5):\n",
                "    axes[0, i].imshow(X_data[i])\n",
                "    axes[0, i].set_title(f'Input 64x64 #{i+1}')\n",
                "    axes[0, i].axis('off')\n",
                "    \n",
                "    axes[1, i].imshow(y_data[i])\n",
                "    axes[1, i].set_title(f'Target 256x256 #{i+1}')\n",
                "    axes[1, i].axis('off')\n",
                "\n",
                "plt.suptitle('Sample Real CelebA Face Images')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. CPU-Optimized U-Net Model (64x64 → 256x256)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_cpu_optimized_unet(input_shape=(64, 64, 3)):\n",
                "    \"\"\"CPU-optimized U-Net for 64x64 → 256x256 super-resolution\"\"\"\n",
                "    inputs = Input(shape=input_shape)\n",
                "    \n",
                "    # Encoder (Contracting Path)\n",
                "    # Block 1\n",
                "    c1 = Conv2D(32, (3, 3), padding='same')(inputs)  # 64x64\n",
                "    c1 = BatchNormalization()(c1)\n",
                "    c1 = Activation('relu')(c1)\n",
                "    c1 = Conv2D(32, (3, 3), padding='same')(c1)\n",
                "    c1 = BatchNormalization()(c1)\n",
                "    c1 = Activation('relu')(c1)\n",
                "    p1 = MaxPooling2D((2, 2))(c1)  # 32x32\n",
                "    \n",
                "    # Block 2\n",
                "    c2 = Conv2D(64, (3, 3), padding='same')(p1)  # 32x32\n",
                "    c2 = BatchNormalization()(c2)\n",
                "    c2 = Activation('relu')(c2)\n",
                "    c2 = Conv2D(64, (3, 3), padding='same')(c2)\n",
                "    c2 = BatchNormalization()(c2)\n",
                "    c2 = Activation('relu')(c2)\n",
                "    p2 = MaxPooling2D((2, 2))(c2)  # 16x16\n",
                "    \n",
                "    # Block 3\n",
                "    c3 = Conv2D(128, (3, 3), padding='same')(p2)  # 16x16\n",
                "    c3 = BatchNormalization()(c3)\n",
                "    c3 = Activation('relu')(c3)\n",
                "    c3 = Conv2D(128, (3, 3), padding='same')(c3)\n",
                "    c3 = BatchNormalization()(c3)\n",
                "    c3 = Activation('relu')(c3)\n",
                "    p3 = MaxPooling2D((2, 2))(c3)  # 8x8\n",
                "    \n",
                "    # Bottleneck\n",
                "    c4 = Conv2D(256, (3, 3), padding='same')(p3)  # 8x8\n",
                "    c4 = BatchNormalization()(c4)\n",
                "    c4 = Activation('relu')(c4)\n",
                "    c4 = Conv2D(256, (3, 3), padding='same')(c4)\n",
                "    c4 = BatchNormalization()(c4)\n",
                "    c4 = Activation('relu')(c4)\n",
                "    \n",
                "    # Decoder (Expanding Path)\n",
                "    # Upsample to 16x16\n",
                "    u5 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c4)  # 16x16\n",
                "    u5 = concatenate([u5, c3])\n",
                "    c5 = Conv2D(128, (3, 3), padding='same')(u5)\n",
                "    c5 = BatchNormalization()(c5)\n",
                "    c5 = Activation('relu')(c5)\n",
                "    c5 = Conv2D(128, (3, 3), padding='same')(c5)\n",
                "    c5 = BatchNormalization()(c5)\n",
                "    c5 = Activation('relu')(c5)\n",
                "    \n",
                "    # Upsample to 32x32\n",
                "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c5)  # 32x32\n",
                "    u6 = concatenate([u6, c2])\n",
                "    c6 = Conv2D(64, (3, 3), padding='same')(u6)\n",
                "    c6 = BatchNormalization()(c6)\n",
                "    c6 = Activation('relu')(c6)\n",
                "    c6 = Conv2D(64, (3, 3), padding='same')(c6)\n",
                "    c6 = BatchNormalization()(c6)\n",
                "    c6 = Activation('relu')(c6)\n",
                "    \n",
                "    # Upsample to 64x64\n",
                "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c6)  # 64x64\n",
                "    u7 = concatenate([u7, c1])\n",
                "    c7 = Conv2D(32, (3, 3), padding='same')(u7)\n",
                "    c7 = BatchNormalization()(c7)\n",
                "    c7 = Activation('relu')(c7)\n",
                "    c7 = Conv2D(32, (3, 3), padding='same')(c7)\n",
                "    c7 = BatchNormalization()(c7)\n",
                "    c7 = Activation('relu')(c7)\n",
                "    \n",
                "    # Additional upsampling for super-resolution\n",
                "    # Upsample to 128x128\n",
                "    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c7)  # 128x128\n",
                "    c8 = Conv2D(16, (3, 3), padding='same')(u8)\n",
                "    c8 = BatchNormalization()(c8)\n",
                "    c8 = Activation('relu')(c8)\n",
                "    c8 = Conv2D(16, (3, 3), padding='same')(c8)\n",
                "    c8 = BatchNormalization()(c8)\n",
                "    c8 = Activation('relu')(c8)\n",
                "    \n",
                "    # Final upsample to 256x256\n",
                "    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same')(c8)  # 256x256\n",
                "    c9 = Conv2D(8, (3, 3), padding='same')(u9)\n",
                "    c9 = BatchNormalization()(c9)\n",
                "    c9 = Activation('relu')(c9)\n",
                "    c9 = Conv2D(8, (3, 3), padding='same')(c9)\n",
                "    c9 = BatchNormalization()(c9)\n",
                "    c9 = Activation('relu')(c9)\n",
                "    \n",
                "    # Output layer\n",
                "    outputs = Conv2D(3, (1, 1), activation='sigmoid')(c9)  # 256x256x3\n",
                "    \n",
                "    model = Model(inputs=[inputs], outputs=[outputs])\n",
                "    return model\n",
                "\n",
                "# Create and compile model\n",
                "print(\"Creating CPU-optimized U-Net model...\")\n",
                "model = create_cpu_optimized_unet(input_shape=(64, 64, 3))\n",
                "\n",
                "print(f\"Input shape: {model.input_shape}\")\n",
                "print(f\"Output shape: {model.output_shape}\")\n",
                "print(f\"Total parameters: {model.count_params():,}\")\n",
                "\n",
                "# Compile with CPU-friendly settings\n",
                "model.compile(\n",
                "    optimizer=Adam(learning_rate=0.001),\n",
                "    loss='mse',\n",
                "    metrics=['mae']\n",
                ")\n",
                "\n",
                "print(\"Model compiled successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Data Preparation and Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data into train and validation sets\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    X_data, y_data, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Training data: {X_train.shape} -> {y_train.shape}\")\n",
                "print(f\"Validation data: {X_val.shape} -> {y_val.shape}\")\n",
                "\n",
                "# CPU-optimized training parameters\n",
                "BATCH_SIZE = 4  # Small batch size for CPU and 256x256 images\n",
                "EPOCHS = 15     # Reasonable for real data\n",
                "\n",
                "# Callbacks for training\n",
                "callbacks = [\n",
                "    EarlyStopping(patience=5, restore_best_weights=True, verbose=1),\n",
                "    ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
                "]\n",
                "\n",
                "print(f\"\\nTraining configuration:\")\n",
                "print(f\"Batch size: {BATCH_SIZE}\")\n",
                "print(f\"Epochs: {EPOCHS}\")\n",
                "print(f\"Using CPU only (no GPU acceleration)\")\n",
                "print(f\"Training on REAL CelebA face images\")\n",
                "\n",
                "# Train the model\n",
                "print(\"\\nStarting training...\")\n",
                "history = model.fit(\n",
                "    X_train, y_train,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    epochs=EPOCHS,\n",
                "    validation_data=(X_val, y_val),\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"Training completed!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}